### 1. 프로그램이 "구성 파일을 찾을 수 없습니다" 또는 "xxxxx는 xxxxx API 키의 구성이 필요합니다"라는 메시지를 표시합니다. 어떻게 해결하나요?

이는 일반적인 설정 문제입니다. 다음과 같은 몇 가지 이유가 있을 수 있습니다:

1. **잘못된 파일 위치 또는 이름:**

* 프로그램은 정확히 `config.toml`이라는 이름의 구성 파일이 필요합니다. 실수로 `config.toml.txt`로 이름을 바꾸지 않았는지 확인하세요.
* 이 파일은 `config` 폴더 안에 위치해야 합니다. 작업 디렉토리의 올바른 구조는 다음과 같아야 합니다:
  ```
  /── config/
  │   └── config.toml
  └── krillinai.exe(실행 파일)
  ```
* **Windows 사용자:** 잠재적인 권한 문제를 피하기 위해 전체 소프트웨어 디렉토리를 C: 드라이브가 아닌 폴더에 두는 것이 좋습니다.

2. **불완전한 API 키 구성:**

* 애플리케이션은 대형 언어 모델(번역용), 음성 서비스(전사 및 음성 합성용) 및 TTS 서비스에 대해 별도의 구성이 필요합니다.
* OpenAI를 모두 사용하더라도 `config.toml` 파일의 서로 다른 섹션에 키를 입력해야 합니다. `llm` 섹션, `transcribe` 섹션, `tts` 섹션을 찾아 해당 API 키 및 기타 필요한 정보를 입력하세요.

### 2. "yt-dlp 오류"가 포함된 오류가 발생합니다. 어떻게 해야 하나요?

이 오류는 비디오 다운로드 프로그램에 문제가 있음을 나타내며, 일반적으로 네트워크 또는 다운로드 프로그램의 버전과 관련이 있습니다.

* **네트워크:** 프록시를 사용하는 경우, `config.toml` 파일 내의 프록시 설정에서 올바르게 구성되었는지 확인하세요.
* **`yt-dlp` 업데이트:** 소프트웨어에 포함된 `yt-dlp` 버전이 구식일 수 있습니다. 소프트웨어의 `bin` 디렉토리에서 터미널을 열고 다음 명령을 실행하여 수동으로 업데이트할 수 있습니다:
  ```
  ./yt-dlp.exe -U
  ```
  
  (운영 체제에 따라 파일 이름이 다를 경우 `yt-dlp.exe`를 올바른 파일 이름으로 교체하세요).

### 3. 최종 비디오의 자막이 깨지거나 사각형 블록으로 나타납니다. 특히 Linux에서 그렇습니다.

이는 거의 항상 시스템에 필요한 글꼴이 누락되어 발생하며, 특히 중국어 문자를 지원하는 글꼴이 필요합니다. 이를 해결하려면 필요한 글꼴을 설치해야 합니다.

1. [Microsoft YaHei](https://modelscope.cn/models/Maranello/KrillinAI_dependency_cn/resolve/master/%E5%AD%97%E4%BD%93/msyh.ttc) 및 [Microsoft YaHei Bold](https://modelscope.cn/models/Maranello/KrillinAI_dependency_cn/resolve/master/%E5%AD%97%E4%BD%93/msyhbd.ttc)와 같은 필요한 글꼴을 다운로드합니다.
2. 새 글꼴 디렉토리를 생성합니다: `sudo mkdir -p /usr/share/fonts/msyh`.
3. 다운로드한 `.ttc` 글꼴 파일을 이 새 디렉토리에 복사합니다.
4. 다음 명령을 실행하여 글꼴 캐시를 재구성합니다:
    ```
    cd /usr/share/fonts/msyh
    sudo mkfontscale
    sudo mkfontdir
    sudo fc-cache -fv
    ```

### 4. macOS에서 애플리케이션이 시작되지 않고 "KrillinAI가 손상되어 열 수 없습니다"라는 오류가 표시됩니다.

이는 macOS의 보안 기능인 Gatekeeper로 인해 발생하며, 이는 확인되지 않은 개발자의 앱을 제한합니다. 이를 해결하려면 수동으로 격리 속성을 제거해야 합니다.

1. **터미널** 앱을 엽니다.
2. `xattr -cr` 명령을 입력한 후 공백을 추가하고, Finder 창에서 `KrillinAI.app` 파일을 터미널로 드래그합니다. 명령은 다음과 비슷하게 보일 것입니다:
    ```
    xattr -cr /Applications/KrillinAI.app
    ```
3. Enter 키를 누릅니다. 이제 애플리케이션을 열 수 있어야 합니다.

### 5. 처리 중에 `ffmpeg 오류`, `audioToSrt 오류` 또는 `exit status 1`과 같은 오류가 발생합니다.

이러한 오류는 일반적으로 종속성 또는 시스템 리소스 문제를 나타냅니다.

* **`ffmpeg 오류`:** 이는 `ffmpeg`가 설치되지 않았거나 시스템의 PATH에서 접근할 수 없음을 나타냅니다. 공식 버전의 `ffmpeg`가 완전하게 설치되어 있고, 그 위치가 시스템 환경 변수에 추가되어 있는지 확인하세요.
* **`audioToSrt 오류` 또는 `exit status 1`:** 이 오류는 전사 단계(오디오-텍스트)에서 발생합니다. 일반적인 원인은 다음과 같습니다:
  * **모델 문제:** 로컬 전사 모델(예: `fasterwhisper`)이 로드되지 않거나 다운로드 중 손상되었습니다.
  * **메모리 부족(RAM):** 로컬 모델을 실행하는 것은 리소스를 많이 소모합니다. 머신의 메모리가 부족해지면 운영 체제가 프로세스를 종료할 수 있으며, 이로 인해 오류가 발생할 수 있습니다.
  * **네트워크 실패:** 온라인 전사 서비스를 사용하는 경우(OpenAI의 Whisper API와 같은), 이는 네트워크 연결 문제 또는 잘못된 API 키를 나타냅니다.

### 6. 진행 표시줄이 움직이지 않습니다. 프로그램이 멈췄나요?

아니요, 오류 메시지가 표시되지 않는 한 프로그램은 작동 중입니다. 진행 표시줄은 주요 작업(예: 전사 또는 비디오 인코딩)이 완전히 완료된 후에만 업데이트됩니다. 이러한 작업은 매우 시간이 많이 소요될 수 있으며, 진행 표시줄이 오랜 시간 동안 멈춘 것처럼 보일 수 있습니다. 인내심을 가지고 작업이 완료될 때까지 기다려 주세요.

### 7. 제 NVIDIA 5000 시리즈 GPU는 `fasterwhisper`에서 지원되지 않습니다. 어떻게 해야 하나요?

`fasterwhisper` 모델이 NVIDIA 5000 시리즈 GPU에서 제대로 작동하지 않을 수 있습니다(2025년 중반 기준). 전사에 대한 몇 가지 대안이 있습니다:

1. **클라우드 기반 모델 사용:** `config.toml` 파일에서 `transcribe.provider.name`을 `openai` 또는 `aliyun`으로 설정합니다. 그런 다음 해당 API 키 및 구성 세부정보를 입력합니다. 이렇게 하면 로컬 모델 대신 클라우드 제공자의 Whisper 모델을 사용하게 됩니다.
2. **다른 로컬 모델 사용:** 원래의 `whisper.cpp`와 같은 다른 로컬 전사 모델을 실험해 볼 수 있습니다.

### 8. 텍스트 음성 변환을 위한 올바른 음성/톤 코드를 어떻게 찾고 입력하나요?

사용 중인 음성 서비스 제공자가 정의한 사용 가능한 음성과 해당 코드가 있습니다. 공식 문서를 참조하세요.

* **OpenAI TTS:** [문서](https://platform.openai.com/docs/guides/text-to-speech/api-reference) (음성 옵션 참조).
* **Alibaba Cloud:** [문서](https://help.aliyun.com/zh/isi/developer-reference/overview-of-speech-synthesis) (톤 목록의 `voice` 매개변수 참조).

### 9. Ollama에서 실행 중인 로컬 대형 언어 모델(LLM)을 번역에 어떻게 사용할 수 있나요?

예, KrillinAI를 OpenAI 호환 API 엔드포인트를 제공하는 로컬 LLM을 사용하도록 구성할 수 있습니다.

1. **로컬 LLM 시작:** 로컬 서비스(예: Ollama에서 Llama3 실행)가 활성화되고 접근 가능해야 합니다.
2. **`config.toml` 편집:** 대형 언어 모델(번역기) 섹션에서:

* 제공자 `name`(또는 `type`)을 `"openai"`로 설정합니다.
* `api_key`를 임의의 문자열(예: `"ollama"`)로 설정합니다. 로컬 호출에는 필요하지 않습니다.
* `base_url`을 로컬 모델의 API 엔드포인트로 설정합니다. Ollama의 경우 일반적으로 `http://localhost:11434/v1`입니다.
* `model`을 제공하는 모델의 이름으로 설정합니다. 예를 들어, `"llama3"`입니다.

### 10. 최종 비디오에서 자막 스타일(글꼴, 크기, 색상)을 사용자 정의할 수 있나요?

아니요. 현재 KrillinAI는 **하드코딩된 자막**을 생성하므로 자막이 비디오 프레임에 직접 삽입됩니다. 애플리케이션은 자막 스타일을 사용자 정의할 수 있는 옵션을 제공하지 않으며, 미리 설정된 스타일을 사용합니다.

고급 사용자 정의를 위해 권장되는 우회 방법은:

1. KrillinAI를 사용하여 번역된 `.srt` 자막 파일을 생성합니다.
2. 원본 비디오와 이 `.srt` 파일을 전문 비디오 편집기(예: Premiere Pro, Final Cut Pro, DaVinci Resolve)에 가져와서 렌더링 전에 사용자 정의 스타일을 적용합니다.

### 11. 이미 번역된 `.srt` 파일이 있습니다. KrillinAI가 이를 사용하여 더빙만 수행할 수 있나요?

아니요, 현재 이 기능은 지원되지 않습니다. 애플리케이션은 전사에서 최종 비디오 생성까지 전체 파이프라인을 실행합니다.